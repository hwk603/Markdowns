title: 网络数据挖掘-课后作业
date: 2016-03-13 23:09:12
tags: homework
comments: false
---


**课程名称**：网络数据挖掘

**实验课时**：3

**试验项目**：爬虫练习

**试验时间**: 2016/3/7

**实验目的**：使用任意方式，爬取特定页面数据信息。

**试验环境**：`windows 10` + `python 2.7` + `pyspider`

<!--more-->

**实验内容**：

- 算法程序

```
#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2016-03-13 22:02:01
# Project: news

from pyspider.libs.base_handler import *

class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl('http://www.scu.edu.cn/cs/', callback=self.index_page)

    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):
        for each in response.doc('a[href^="http"]').items():
            self.crawl(each.attr.href, callback=self.detail_page)

    @config(priority=2)
    def detail_page(self, response):
        return {
            "url": response.url,
            "title": response.doc('title').text(),
        }

```
- 步骤方法：

1. 终端启动pyspider
![启动][1]

2. 创建爬虫任务
![创建][2]

3. 配置任务
![配置][3]

4. 开始任务
![开始1][4]
![开始2][5]

5. 查看结果
![结果1][6]
![结果2][7]
![结果3][8]
![结果4][9]

- 结论结果：

通过安装配置和使用 `pyspider` 爬虫架构，对定向抓取和结构化化解析有了一定的理解；了解了 `pyspider` 的架构设计组成；在 web 的可视化任务监控下，体验了web脚本编写和单步调试。


  [1]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%201.png
  [2]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%202.png
  [3]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%203.png
  [4]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%204.png
  [5]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%205.png
  [6]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%206.png
  [7]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%207.png
  [8]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%208.png
  [9]: http://7i7k6x.com1.z0.glb.clouddn.com/pyspider-Image%209.png